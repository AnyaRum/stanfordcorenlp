{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stanfordcorenlp import StanfordCoreNLP\n",
    "import logging\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please first run from the command line: pip install stanfordcorenlp\n",
    "from stanfordcorenlp import StanfordCoreNLP\n",
    "\n",
    "# specify the path to the stanford-corenlp-full-2018-10-05 and the language in use with CoreNLP parameters\n",
    "nlp = StanfordCoreNLP(r'/media/carpediemmlf/MyPassport/Data/stanfordcorenlp/stanford-corenlp-full-2018-10-05', lang='en', quiet = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Close Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.close() # Do not forget to close! The backend server will consume a lot memery."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Initializing native server...\n",
      "INFO:root:java -Xmx4g -cp \"/media/carpediemmlf/MyPassport/Data/stanfordcorenlp/stanford-corenlp-full-2018-10-05/*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001\n",
      "INFO:root:Server shell PID: 25600\n",
      "INFO:root:Waiting until the server is available.\n",
      "INFO:root:Waiting until the server is available.\n",
      "INFO:root:The server is available.\n",
      "INFO:root:{'properties': \"{'annotators': 'ssplit,tokenize', 'outputFormat': 'json'}\", 'pipelineLanguage': 'en'}\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): localhost:9001\n",
      "DEBUG:urllib3.connectionpool:http://localhost:9001 \"POST /?properties=%7B%27annotators%27%3A+%27ssplit%2Ctokenize%27%2C+%27outputFormat%27%3A+%27json%27%7D&pipelineLanguage=en HTTP/1.1\" 200 2357\n",
      "INFO:root:{'properties': \"{'annotators': 'pos', 'outputFormat': 'json'}\", 'pipelineLanguage': 'en'}\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): localhost:9001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenize: ['Guangdong', 'University', 'of', 'Foreign', 'Studies', 'is', 'located', 'in', 'Guangzhou', '.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:http://localhost:9001 \"POST /?properties=%7B%27annotators%27%3A+%27pos%27%2C+%27outputFormat%27%3A+%27json%27%7D&pipelineLanguage=en HTTP/1.1\" 200 2593\n",
      "INFO:root:{'properties': \"{'annotators': 'ner', 'outputFormat': 'json'}\", 'pipelineLanguage': 'en'}\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): localhost:9001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part of Speech: [('Guangdong', 'NNP'), ('University', 'NNP'), ('of', 'IN'), ('Foreign', 'NNP'), ('Studies', 'NNPS'), ('is', 'VBZ'), ('located', 'JJ'), ('in', 'IN'), ('Guangzhou', 'NNP'), ('.', '.')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:http://localhost:9001 \"POST /?properties=%7B%27annotators%27%3A+%27ner%27%2C+%27outputFormat%27%3A+%27json%27%7D&pipelineLanguage=en HTTP/1.1\" 200 3748\n",
      "INFO:root:{'properties': \"{'annotators': 'pos,parse', 'outputFormat': 'json'}\", 'pipelineLanguage': 'en'}\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): localhost:9001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Named Entities: [('Guangdong', 'ORGANIZATION'), ('University', 'ORGANIZATION'), ('of', 'ORGANIZATION'), ('Foreign', 'ORGANIZATION'), ('Studies', 'ORGANIZATION'), ('is', 'O'), ('located', 'O'), ('in', 'O'), ('Guangzhou', 'CITY'), ('.', 'O')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:http://localhost:9001 \"POST /?properties=%7B%27annotators%27%3A+%27pos%2Cparse%27%2C+%27outputFormat%27%3A+%27json%27%7D&pipelineLanguage=en HTTP/1.1\" 200 8182\n",
      "INFO:root:{'properties': \"{'annotators': 'depparse', 'outputFormat': 'json'}\", 'pipelineLanguage': 'en'}\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): localhost:9001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constituency Parsing: (ROOT\n",
      "  (S\n",
      "    (NP\n",
      "      (NP (NNP Guangdong) (NNP University))\n",
      "      (PP (IN of)\n",
      "        (NP (NNP Foreign) (NNPS Studies))))\n",
      "    (VP (VBZ is)\n",
      "      (VP (JJ located)\n",
      "        (PP (IN in)\n",
      "          (NP (NNP Guangzhou)))))\n",
      "    (. .)))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:http://localhost:9001 \"POST /?properties=%7B%27annotators%27%3A+%27depparse%27%2C+%27outputFormat%27%3A+%27json%27%7D&pipelineLanguage=en HTTP/1.1\" 200 7947\n",
      "INFO:root:Cleanup...\n",
      "INFO:root:Killing pid: 25601, cmdline: ['java', '-Xmx4g', '-cp', '/media/carpediemmlf/MyPassport/Data/stanfordcorenlp/stanford-corenlp-full-2018-10-05/*', 'edu.stanford.nlp.pipeline.StanfordCoreNLPServer', '-port', '9001']\n",
      "INFO:root:Killing shell pid: 25600, cmdline: ['/bin/sh', '-c', 'java -Xmx4g -cp \"/media/carpediemmlf/MyPassport/Data/stanfordcorenlp/stanford-corenlp-full-2018-10-05/*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependency Parsing: [('ROOT', 0, 7), ('compound', 2, 1), ('nsubjpass', 7, 2), ('case', 5, 3), ('compound', 5, 4), ('nmod', 2, 5), ('auxpass', 7, 6), ('case', 9, 8), ('nmod', 7, 9), ('punct', 7, 10)]\n"
     ]
    }
   ],
   "source": [
    "# Simple usage\n",
    "\n",
    "\n",
    "sentence = 'Guangdong University of Foreign Studies is located in Guangzhou.'\n",
    "print ('Tokenize:', nlp.word_tokenize(sentence))\n",
    "print ('Part of Speech:', nlp.pos_tag(sentence))\n",
    "print ('Named Entities:', nlp.ner(sentence))\n",
    "print ('Constituency Parsing:', nlp.parse(sentence))\n",
    "print ('Dependency Parsing:', nlp.dependency_parse(sentence))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using an existing server http://localhost:9000\n",
      "INFO:root:Waiting until the server is available.\n",
      "INFO:root:Waiting until the server is available.\n",
      "INFO:root:Waiting until the server is available.\n",
      "INFO:root:Waiting until the server is available.\n",
      "INFO:root:Waiting until the server is available.\n",
      "INFO:root:Waiting until the server is available.\n",
      "INFO:root:Waiting until the server is available.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-0b16806d5452>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;31m#     print (\"Dep Parse:\", sNLP.dependency_parse(text))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m \u001b[0msNLP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStanfordNLP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'A blog post using Stanford CoreNLP Server. Visit www.khalidalnajjar.com for more details.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0msNLP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-0b16806d5452>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, host, port)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'http://localhost'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m9000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         self.nlp = StanfordCoreNLP(host, port = port, \\\n\u001b[0;32m----> 4\u001b[0;31m                                     timeout = 30000,quiet = False, logging_level = logging.DEBUG)\n\u001b[0m\u001b[1;32m      5\u001b[0m         self.props = {\n\u001b[1;32m      6\u001b[0m             \u001b[0;34m'annotators'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'tokenize,ssplit,pos,lemma,ner,parse,depparse,decoref,relation'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/stanfordcorenlp/corenlp.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_host, port, memory, lang, timeout, quiet, logging_level)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect_ex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Waiting until the server is available.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The server is available.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class StanfordNLP:\n",
    "    def __init__(self, host = 'http://localhost', port = 9000):\n",
    "        self.nlp = StanfordCoreNLP(host, port = port, \\\n",
    "                                    timeout = 30000,quiet = False, logging_level = logging.DEBUG)\n",
    "        self.props = {\n",
    "            'annotators': 'tokenize,ssplit,pos,lemma,ner,parse,depparse,decoref,relation',\n",
    "            'pipelineLanguage': 'en',\n",
    "            'outputFormat': 'json'\n",
    "        }\n",
    "        \n",
    "    def word_tokenize(self, sentence):\n",
    "        return self.nlp.word_tokenize(sentence)\n",
    "    \n",
    "    def pos(self, sentence):\n",
    "        return self.nlp.pos_tag(sentence)\n",
    "    \n",
    "    def ner(self, sentence):\n",
    "        return self.nlp.ner(sentence)\n",
    "    \n",
    "    def parse(self, sentence):\n",
    "        return self.nlp.parse(sentence)\n",
    "    \n",
    "    def dependency_parse(self, sentence):\n",
    "        return self.nlp.dependency_parse(sentence)\n",
    "    \n",
    "    def annotate(self, sentence):\n",
    "        return json.loads(self.nlp.annotate(sentence, properties = self.props))\n",
    "    \n",
    "    @staticmethod\n",
    "    def tokens_to_dict(_tokens):\n",
    "        tokens = defaultdict(dict)\n",
    "        for token in _tokens:\n",
    "            tokens[int(token['index'])] = {\n",
    "                'word': token['word'],\n",
    "                'lemma': token['lemma'],\n",
    "                'pos': token['pos'],\n",
    "                'ner': token['ner']\n",
    "            }\n",
    "        return tokens\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     sNLP = StanfordNLP()\n",
    "#     text = 'A blog post using Stanford CoreNLP Server. Visit www.khalidalnajjar.com for more details.'\n",
    "#     print (\"Annotate:\"+ sNLP.annotate(text))\n",
    "#     print (\"POS:\", sNLP.pos(text))\n",
    "#     print (\"Tokens:\", sNLP.word_tokenize(text))\n",
    "#     print (\"NER:\", sNLP.ner(text))\n",
    "#     print (\"Parse:\", sNLP.parse(text))\n",
    "#     print (\"Dep Parse:\", sNLP.dependency_parse(text))\n",
    "\n",
    "sNLP = StanfordNLP()\n",
    "text = 'A blog post using Stanford CoreNLP Server. Visit www.khalidalnajjar.com for more details.'\n",
    "sNLP.annotate(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
